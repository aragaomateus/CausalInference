---
title: "Problem Set 1"
author: "Mateus Silva Aragao - msa8779 - 001 "
date: "Due Oct 7th, 2022"
output:
  pdf_document: default
---

This homework must be turned in on Brightspace by Oct 7th 2022. It must be your own work, and your own work only -- you must not copy anyone's work, or allow anyone to copy yours. This extends to writing code. You may consult with others, but when you write up, you must do so alone.

Your homework submission must be written and submitted using Rmarkdown. No handwritten solutions
will be accepted. You should submit:

1. A compiled PDF file named yourNetID_solutions.pdf containing your solutions to the problems.

2. A .Rmd file containing the code and text used to produce your compiled pdf named yourNetID_solutions.Rmd.


Note that math can be typeset in Rmarkdown in the same way as Latex. Please make sure your answers are clearly structured in the Rmarkdown file:

1. Label each question part

2. Do not include written answers as code comments.

3. The code used to obtain the answer for each question part should accompany the written answer. Comment your code!

\newpage 

# Definitions and Examples (20 points)
Answer the following questions. Be as specific and detailed as possible. Give examples.

1. What is the fundamental problem of causal inference?
### Answer: 
The fundamental problem of causal inference is that we can not observe potential outcomes under the same conditions. In a controlled experiment, we can only observe the outcomes of the treatment on the subjects that received treatment and observe the outcomes of not receiving the treatment on those subjects that did not receive the treatment. We can not observe the outcome of not receiving the treatment in a subject that did receive the treatment, and vice versa. 

2. Why are experiments important?
### Answer: 
Experiments are important because it enables the researcher to set up a controlled environment where they can prove their hypothesis by controlling for cofounders and other externalities. By designing an experiment, the researcher can achieve a causal effect in their experiment, because of that controlled environment, something that is hard to achieve through solely observable data/experiment.  

3. What does ignorability mean?
### Answer: 
It means that treatments are assigned independent of the outcome of the. Meaning that if my method for randomized the experiment is flipping a fair coin, the probability of receiving heads or tails(treatment or control) does not influence the potential outcomes.  


4. What is SUTVA?
### Answer:
For an experiment to follow STUVA, it must guarantee 2  conditions: 

- No A single version of treatment must be applied to all subjects in the treatment group. (single version of treatment )

- The assignment of a subject to treatment does not influence the outcomes of other subjects. (No spillover)

Example: If your treatment is a tutor teaching you math before a math test. Each student assigned to this treatment would have to be taught by the same tutor, during the same period, using the same materials, etc... To guarantee the no spillover condition, each student would have to wait outside of the classroom and be made sure that none of the students waiting can listen to the lecture through the door. 

# Application (Coding) (20 points)
The STAR (Student-Teacher Achievement Ratio) Project is a four year
*longitudinal study* examining the effect of class size in early
grade levels on educational performance and personal
development. 

This exercise is in part based on:
 Mosteller, Frederick. 1997. “[The Tennessee Study of Class Size in the 
 Early School Grades.](http://dx.doi.org/10.2307/3824562)” *Bulletin of 
 the American Academy of Arts and Sciences* 50(7): 14-25.
  
A longitudinal study is one in which the same
participants are followed over time.  This particular study lasted
from 1985 to 1989 involved 11,601 students. During the four years of
the study, students were randomly assigned to small classes,
regular-sized classes, or regular-sized classes with an aid.  In all,
the experiment cost around $12 million. Even though the program
stopped in 1989 after the first kindergarten class in the program
finished third grade, collection of various measurements (e.g.,
performance on tests in eighth grade, overall high school GPA)
continued through the end of participants' high school attendance.

We will analyze just a portion of this data to investigate whether the
small class sizes improved performance or not. The data file name is
`STAR.csv`, which is a CSV data file.  The names and
descriptions of variables in this data set are:


 Name                 Description
 -------------------- ----------------------------------------------------------
 `race`               Student's race (White = 1, Black = 2, Asian = 3, Hispanic = 4,  Native American = 5, Others = 6)
 `classtype`          Type of kindergarten class (small = 1, regular = 2, regular with aid = 3)
 `g4math`             Total scaled score for math portion of fourth grade standardized test 
 `g4reading`          Total scaled score for reading portion of fourth grade standardized test 
 `yearssmall`         Number of years in small classes 
 `hsgrad`             High school graduation (did graduate = 1, did not graduate = 0) 
 
Note that there are a fair amount of missing
values in this data set.  For example, missing values arise because
some students left a STAR school before third grade or did not enter a
STAR school until first grade.

1. Create a new factor variable called `kinder` in the data
  frame.  This variable should recode `classtype` by changing
  integer values to their corresponding informative labels (e.g.,
  change 1 to `small` etc.).  Similarly, recode the
  `race` variable into a factor variable with four levels
  (`white`, `black`, `hispanic`, `others`) by
  combining Asians and Native Americans as the `others`
  category.  For the `race` variable, overwrite the original
  variable in the data frame rather than creating a new one.  Recall
  that `na.rm = TRUE` can be added to functions in order to
  remove missing data.

```{r}
library(dplyr)

## read in data
STAR <- read.csv("STAR.csv")
# Things to do in this chunk :

# Create a new factor variable called `kinder` in the data
#   frame.  This variable should recode `classtype` by changing
#   integer values to their corresponding informative labels (e.g.,
#   change 1 to `small` etc.)
STAR = STAR %>% mutate(kinder = case_when(classtype == '1' ~ "small",classtype == '2' ~ "regular",classtype == '3' ~ "regular with aid"))

# recode the
#   `race` variable into a factor variable with four levels
#   (`white`, `black`, `hispanic`, `others`) by
#   combining Asians and Native Americans as the `others`
#   category. ----(For the `race` variable, overwrite the original
  # variable in the data frame rather than creating a new one.  Recall
  # that `na.rm = TRUE` can be added to functions in order to
  # remove missing data)---
STAR = STAR %>% mutate(race = case_when(race == '1' ~ "white",race == '2' ~ "black",race == '4' ~ "hispanic", race == '3'~ "others",race == '5'~ "others",race == '6'  ~ "others"),na.rm = FALSE)
head(STAR,5)                             

```

2. How does performance on fourth grade reading and math tests for
  those students assigned to a small class in kindergarten compare
  with those assigned to a regular-sized class?  Do students in the
  smaller classes perform better?  Use means to make this comparison
  while removing missing values.  Give a brief substantive
  interpretation of the results.  To understand the size of the
  estimated effects, compare them with the standard deviation of the
  test scores.
 
```{r}

grad4_small = STAR %>% filter(kinder=='small') %>% filter(!is.na(g4math) & !is.na(g4reading))

# mean and standard deviation for math scores on small class 
grad4_small_math_mean = mean(grad4_small$g4math)
grad4_small_math_std = sd(grad4_small$g4math)

grad4_small_math_mean
grad4_small_math_std

# mean and standard deviation for reading scores on small class 
grad4_small_read_mean = mean(grad4_small$g4reading)
grad4_small_read_std = sd(grad4_small$g4reading)

grad4_small_read_mean
grad4_small_read_std

grad4_regular = STAR %>% filter(kinder=='regular') %>% filter(!is.na(g4math) & !is.na(g4reading))

# mean and standard deviation for math scores on regular class 
grad4_regular_math_mean = mean(grad4_regular$g4math)
grad4_regular_math_std = sd(grad4_regular$g4math)

grad4_regular_math_mean
grad4_regular_math_std

# mean and standard deviation for reading scores on regular class 
grad4_regular_read_mean = mean(grad4_regular$g4reading)
grad4_regular_read_std = sd(grad4_regular$g4reading)

grad4_regular_read_mean
grad4_regular_read_std
```
### Conclusions:
For math scores, there is no significant difference in the means. The standard deviations for the regular-size class are smaller which might indicate that the performance in the regular-size class was similar among their peers.
For the reading scores, the small-sized class performed slightly better by comparing the mean score and the standard deviation for that class was smaller, which might indicate that the students performed closely on that type of test. 

3. Instead of comparing just average scores of reading and math
  tests between those students assigned to small classes and those
  assigned to regular-sized classes, look at the entire range of
  possible scores.  To do so, compare a high score, defined as the
  66th percentile, and a low score (the 33rd percentile) for small
  classes with the corresponding score for regular classes.  These are
  examples of *quantile treatment effects*.  Does this analysis
  add anything to the analysis based on mean in the previous question? (Hint: You will use the quantile() function in r.)
```{r}

#taking the quantiles for the small class
quantile(grad4_small$g4math,na.rm = T,probs = c(0.33,0.66))


quantile(grad4_small$g4reading,na.rm = T,probs = c(0.33,0.66))

#taking the quantile for the regular size class
quantile(grad4_regular$g4math,na.rm = T,probs = c(0.33,0.66))


quantile(grad4_regular$g4reading,na.rm = T,probs = c(0.33,0.66))
```
### Conclusions:
In general, the scores for the small class upper quantile were higher. 
But the difference is so small that just looking at the means might not be enough to conclude the actual impact this treatment had. Also, the groups might contain individuals who would be going to get a good score regardless of the treatment received.

4. We examine whether the STAR program reduced the achievement gaps
  across different racial groups.  Begin by comparing the average
  reading and math test scores between white and minority students
  (i.e., Blacks and hispanics) among those students who were assigned
  to regular classes with no aid.  Conduct the same comparison among
  those students who were assigned to small classes.  Give a brief
  substantive interpretation of the results of your analysis.
  
```{r}
# this chunk will contain only code for the regular class.

# white group in the regular class
regularClass_white = STAR %>% filter(race=='white' & kinder =='regular' ) %>% filter(!is.na(g4math) & !is.na(g4reading))

# computing stats
regularClass_white  = regularClass_white %>% group_by(race)  %>%
                    summarise(mean_math = mean(g4math),
                              mean_read = mean(g4reading),
                              .groups = 'drop')

regularClass_white

regularClass_minority = STAR %>% filter((race=='hispanic'| race=='black' ) & kinder =='regular') %>% filter(!is.na(g4math) & !is.na(g4reading))

# computing stats for the minority group
regularClass_minority = regularClass_minority %>% group_by(race)  %>%
                    summarise(mean_math = mean(g4math),
                              mean_read = mean(g4reading),
                              .groups = 'drop')
regularClass_minority

# showing the difference in the means of the groups
dif_mean_math = (regularClass_white$mean_math - regularClass_minority$mean_math)
cat("difference on mean math scores:",dif_mean_math)

dif_mean_read = (regularClass_white$mean_read - regularClass_minority$mean_read)
cat("\ndifference on reading scores:",dif_mean_read)
```

```{r}
# this chunk will contain only code for the small class.

# white group in the small class
smallClass_white = STAR %>% filter(race=='white' & kinder =='small' ) %>% filter(!is.na(g4math) & !is.na(g4reading))

# computing stats
smallClass_white  = smallClass_white %>% group_by(race)  %>%
                    summarise(mean_math = mean(g4math),
                              mean_read = mean(g4reading),
                              .groups = 'drop')

smallClass_white

# there are only 5 hispanic kids on the dataset, lol? 
smallClass_minority = STAR %>% filter((race=='hispanic'| race=='black') & kinder =='small') %>% filter(!is.na(g4math) & !is.na(g4reading))

# computing stats for the minority group
smallClass_minority = smallClass_minority %>% group_by(race)  %>%
                    summarise(mean_math = mean(g4math),
                              mean_read = mean(g4reading),
                              .groups = 'drop')
smallClass_minority

# showing the difference in the means of the groups
dif_mean_math = (smallClass_white$mean_math - smallClass_minority$mean_math)
cat("difference on math scores:",dif_mean_math)
dif_mean_read = (smallClass_white$mean_read - smallClass_minority$mean_read)
cat("\ndifference on reading scores:",dif_mean_read)
```
### Conclusions:
By comparing the means of the scores 
5. We consider the long term effects of kindergarden class size.
  Compare high school graduation rates across students assigned to
  different class types.  Also, examine whether graduation rates
  differ by the number of years spent in small classes.  Finally, as
  done in the previous question, investigate whether the STAR program
  has reduced the racial gap between white and minority students'
  graduation rates.  Briefly discuss the results.
```{r}
#Compare high school graduation rates across students assigned to
# different class types 
# which classes give the highest chance of graduating in high school
computed_graduation = STAR %>% filter(hsgrad==1 | hsgrad==0 )
graduation_small = computed_graduation %>% filter(kinder=='small')
graduation_regular = computed_graduation %>% filter(kinder=='regular')
graduation_regular_aid = computed_graduation %>% filter(kinder=='regular with aid')
cat("\n small class rate:",mean(graduation_small$hsgrad ))
cat("\n regular class rate:",mean(graduation_regular$hsgrad ))
cat("\n regular_aid class rate:",mean(graduation_regular_aid$hsgrad ))

# examine whether graduation rates differ by the number of years spent in small classes
# the longer the student spent in a small classroom, the larger the graduation rate ?
smallClass_years_graduation = computed_graduation %>% group_by(yearssmall)  %>%
                    summarise(mean_math = mean(hsgrad),
                              .groups = 'drop')
smallClass_years_graduation
# graduation rate in between race within the small class?

race_graduation_regular = graduation_regular %>% group_by(race)  %>%
                    summarise(graduation_rate = mean(hsgrad),
                              .groups = 'drop')
race_graduation_small = graduation_small %>% group_by(race)  %>%
                    summarise(graduation_rate = mean(hsgrad),
                              .groups = 'drop')
race_graduation_regular
race_graduation_small
```
Students that were assigned to the regular class had a slightly worse performance compared with students in other classes. Students in the small class and regular with aid had a similar graduation rate. 
The difference in years spent in the small class was very significant showing as much as an 8% difference. This indicates that spending more years on that class format might have helped you in overall high school performance. 

By comparing races, it was possible to observe that both black and white students had a slight increase in graduation rates when comparing small classes and regular classes. In both cases, white students had a large graduation rate. 


# Bed Nets and Malaria (20 points)

Article: Free Distribution or Cost-Sharing? Evidence from a Randomized Malaria Prevention Experiment
by Jessica Cohen and Pascaline Dupas

Some economists have argued that ``cost-sharing" makes it more likely that a product will be used (versus giving it away for free). Cohen and Dupas partnered with 20 Kenyan prenatal clinics to distribute subsidized anti-malarial bed nets. For each clinic, they varied the extent of the subsidy: either full (free bed-nets, $D_i = 1$) or partial (90\% cheaper bed-nets, $D_i = 0$). They measure (among other things) whether women who received bed nets used them ($Y_i$).


1. What is $\mathbb{E}[Y_i | D_i = 0]$?
### Answer: 
The expectation of the outcome of people who did not received the treatment.
2. What is $\mathbb{E}[Y_i(1)]$?
### Answer:
The expectation of the positive outcomes. 

3. What is $\mathbb{E}[Y_i(1) | D_i = 0]$?
### Answer:
The expectation of obversing a positive outcome given that the subject did not receive the treatment.

4. Cohen and Dupas randomized treatment at the level of the clinic,
but the outcomes of interest are at the individual level. Is there a violation of consistency/SUTVA? Why or why not? Argue your case. 

### Answer:
No, This experiment is similar to a block experiment. In which the clinics are the blocks and all patients in the clinic are receiving either the treatment or control. Therefore it does not violate any condition.



# Let's Help a Small Business! (20 points)

1. Imagine you are a consultant working with a restaurant to increase their number of customers. In the past, the owner spent a lot of money sending a postcard to every individual in the city. The owner says that every time they send out postcards, there's an increase in their business. Is the relationship between sending postcards and increased business for the restaurant causal? What do you need to know to say that this is a causal relationship? Be specific and give examples.

### Answer: 
It could be causal, or could just be a correlation. Given the events that have already happened, it would be better to compare the current restaurant attendance with the one registered the year before, right after sending the postcards. This way we would be measuring the same event on similar conditions, one year apart. 
It would be good to know the time of the year. As someone who has worked in the restaurant industry, different time of the year attracts a different influx of people. Let's assume a very popular date across the USA that tends to be standard no matter the city: Mother's day or valentines day. If the owner sent the postcards right before mothers day or valentines day period, they would register a significant uptick in sales just because of the event itself, but they could associate the increase in sales with their campaign. 
It would be good if the owner offered any deals on the postcard: Bring this card and get 25% off. 


2. Imagine you are designing an experiment for this small business. You want to know whether advertising (sending a postcard) will increase a person's probability of going to the restaurant. How would you do it? (Detail what kind of experiment you would run. Explain how and why the experiment will provide an average treatment effect. What assumptions do you need to be true for the experiment to be causal.)

### Answer:
The ideal experiment to prove that such a business strategy would increase would be to randomly send a postcard to every person in a household at the beginning of a month. And then we would be computing throughout the whole month if the person/group of people that came into the restaurant received the postcard. We would be able to know how many people in that month came into the restaurant because of the postcard and how many did not receive the postcard. 

\newpage
# ATE (20 points)

A study of 10 dancers took place last year. The researchers wanted to know whether new shoes improved the dancers performance. We denote T = 1 to mean that the dancers received new shoes and T = 0 to mean the dancers used old shoes. 

The table below contains the data. For each dancer, we know whether they were assigned to the treatment (T = 1) or control group (T = 0). We also see their observed outcome or quality of performance on a 0 to 100 scale. Lastly, we have information about whether the individual is currently a dance trainer (instructor) denoted by DT={yes, no}. Note: The empty cells indicate the counterfactual outcomes that are not possible to observe.



 Dancer | Trainer(DT) | T | Y(1) | Y(0) 
:------:|:-----------:|:---:|:----:|:----:
 1      | Yes           | 1 | 60   |      
 2      | Yes           | 1 | 75   |      
 3      | Yes           | 1 | 53   |      
 4      | Yes           | 1 | 69   |      
 5      | Yes           | 0 |      | 63   
 6      | No           | 1 | 50   |      
 7      | No           | 0 |      | 42   
 8      | No           | 0 |      | 50   
 9      | No           | 0 |      | 58   
 10     | No           | 0 |      | 59   






1. Estimate the ATE using the data in the table.
$$ ATE_1 = E[Y|T = 1] - E[Y|T = 0] $$
```{r}

Y_1 = c(60,75,53,69,50)
Y_0 = c(63,42,50,58,59)

ate_1 = mean(Y_1) - mean(Y_0)
ate_1
```

2. As we can see from the data, the treatment was given mostly to dance trainers. Now compute the dance-trainer-specific effect using the data in the table.
$$ ATE_2 =E_{P(DT)}[E[Y|T = 1,DT=Yes] - E[Y|T = 0,DT=Yes]] $$
```{r}

Y_1_dt = c(60,75,53,69)
Y_0_dt = c(63)

ate_2 = mean(Y_1_dt) - mean(Y_0_dt)
ate_2
```

3. Which one of $ATE_1$ and $ATE_2$ estimates the ATE better? Briefly explain your choice.
### Answer: 
The second option. Because it looks for the treatment effect within a specific group. So this was more like a stratified ATE. We were comparing the outcomes between people of the same expertise, therefore effect would be more representative of how it changes the performances. 
This is also an example of controlling a cofounder.


## Design Your Experiment (20 points)

Design your own experiment from start to finish. Choose an *interesting* question. Explain why observational data may give you the wrong answer. Detail the potential outcomes and a well-defined treatment. Explain the type of experiment (completely random, cluster-design, block/stratified). Will your design ensure a causal treatment effect? (Remember: Be as specific as possible and give examples.)

### Answer:
- The Question:
Can background noise levels affect how well we concentrate?

- The Experiment: 
Students will read a text for a certain amount of time from 2 pm to 4 pm. During this time
we will experiment with the effect of white noise while studying, library(Bobst 5th-floor noise) noise background while studying, and calm music while studying. 

After a pre-determined time of the study, the students will have to write a summary of the text read. Students regardless of treatment will be relocated to a quiet room where they will be able to write the text.

A single professor will grade the summaries without being aware of the treatment applied to the students. Students will be stratified by major.

- The observational data:
Given that we could collect observational data from the students' essay scores in writing classes. The observation of this information could contain a lot of cofounders, such as the student is used to writing essays in that setting or the students hold some predisposition for writing in noisy environments.

- Potential outcomes and the treatment:
Potential outcomes are scoring above average and scoring below the average of all the students. Treatment is either calm music or white noise. Control is just the current noise at the library. 

- What type of treatment:
Stratified random experiment. Stratified by college majors.
Within each major, students will be assigned the treatment or control. 
Different majors might be a cofounder for different styles of reading expertise.
